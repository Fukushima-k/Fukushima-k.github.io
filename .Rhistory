# ニュースデータ
news_data <- list(
list(
title = "新しいホームページを公開します。",
date = "2024-07",
content = paste0("新しいホームページを公開します。内容は順次更新予定です。", html_url("https://fukushima-k.github.io/"))
),
list(
title = "共同研究を開始しました。",
date = "2024-06",
content = "外部機関との共同研究を開始しました。今後、公開予定です。"
),
list(
title = "論文が採択されました。",
date = "2024-05",
content =
paste0("<i>Journal of Educational and Behavioral Statistics</i>誌に採択された論文がOnlineFirstで公開されました。", html_url("https://doi.org/10.3102/10769986241245707"))
),
list(
title = "賞を受賞しました。",
date = "2023-11",
content = "日本計算機統計学会 第37回シンポジウムにて「一般化多枝選択型認知診断モデルの提案」の題目で学生研究発表賞をいただきました。ありがとうございます。"
),
list(
title = "preprintを公開しました。",
date = "2023-07",
content = paste0("Open Science Frameworkにて、preprint \"<i>Modeling Partial Knowledge in Multiple-Choice Cognitive Diagnostic Assessment.</i>\" を公開しました。", html_url("https://doi.org/10.31234/osf.io/wefb7"))
)
# 他のニュース項目を追加
)
# ニュース項目をHTMLリストとして生成
generate_news_list <- function(news_items) {
unlist(lapply(news_items, function(item) {
paste0(
'<li class="list-group-item">',
'<h5>', item$title, '</h5>',
'<small>投稿日: ', item$date, '</small>',
'<p>', item$content, '</p>',
'</li>'
)
}))
}
# ニュースページのコンテンツ
news_page_content <- c(
'<h2>ニュース</h2>',
'<ul class="list-group">',
generate_news_list(news_data),
'</ul>'
)
# ニュースページのコンテンツファイルに書き込み
writeLines(news_page_content, "contents/news_content.html")
# 最新の3件を取得
latest_news <- news_data[1:min(3, length(news_data))]
# トップページのニュースセクション
index_news_content <- c(
'<h2>最新のニュース</h2>',
'<ul class="list-group">',
generate_news_list(latest_news),
'</ul>',
'<a href="news.html" class="btn btn-secondary mt-3">すべてのニュースを見る</a>'
)
# トップページのコンテンツファイル（例: contents/index_content.html）に埋め込む
# プレースホルダーを使用して、ニュースセクションを挿入
index_content <- readLines("contents/index_content_news_plus.html", encoding = "UTF-8")
index_content <- str_replace(index_content, fixed("{{news_section}}"), paste(index_news_content, collapse = "\n"))
writeLines(index_content, "contents/index_content_news_plus_written.html", useBytes = TRUE)
# ページ情報のリストを作成
pages <- list(
list(
filename = "index.html",
title = "心理統計学者のホームページ - ホーム",
# content_file = "contents/index_content.html",
content_file = "contents/index_content_news_plus_written.html",
active_menu = "home"
),
list(
filename = "about.html",
title = "心理統計学者のホームページ - 自己紹介",
content_file = "contents/about_content.html",
active_menu = "about"
),
list(
filename = "research.html",
title = "心理統計学者のホームページ - 研究内容",
content_file = "contents/research_content.html",
active_menu = "research"
),
list(
filename = "publications.html",
title = "心理統計学者のホームページ - 業績一覧",
content_file = "contents/publications_content.html",
active_menu = "publications"
),
list(
filename = "news.html",
title = "心理統計学者のホームページ - ニュース",
content_file = "contents/news_content.html",
active_menu = "news"
),
# list(
#   filename = "blog.html",
#   title = "心理統計学者のホームページ - ブログ",
#   content_file = "contents/blog_content.html",
#   active_menu = "blog"
# ),
list(
filename = "index_en.html",
title = "English Version - Coming Soon",
content_file = "contents/index_en_content.html",
active_menu = ""  # ヘッダーにリンクを追加しないため、active_menu は空にします
),
list(
filename = "contact.html",
title = "心理統計学者のホームページ - お問い合わせ",
content_file = "contents/contact_content.html",
active_menu = "contact"
)
)
# 各ページのHTMLを生成
for (page in pages) {
# ヘッダーのテンプレートにタイトルを挿入
header <- str_replace_all(header_template, fixed("{{title}}"), page$title)
# アクティブなメニューを設定
menu_items <- c("home", "about", "research", "publications", "blog", "contact")
for (item in menu_items) {
if (item == page$active_menu) {
header <- str_replace_all(header, fixed(paste0("{{active_", item, "}}")), "active")
} else {
header <- str_replace_all(header, fixed(paste0("{{active_", item, "}}")), "")
}
}
# コンテンツを読み込み
content <- readLines(page$content_file, encoding = "UTF-8")
# フッターをそのまま使用
footer <- footer_template
# 最終的なHTMLを組み立て
html <- c(header, content, footer)
# ファイルに書き込み
writeLines(html, page$filename, useBytes = TRUE)
cat("Generated:", page$filename, "\n")
}
# 必要なライブラリをインストール
# install.packages("openssl")
# install.packages("httr")
# ライブラリの読み込み
library(openssl)
library(httr)
library(jsonlite)
library(tidyverse)
convert_name <- function(name) {
# 名前がすでにFamily name + イニシャル形式の場合
if (grepl("^[A-Za-z]+, [A-Za-z]\\.*$", name)) {
if (grepl("^[A-Za-z]+, [A-Za-z]\\.$", name))
return(name)
else
return(paste0(name, "."))
}
# First name + Family nameの場合、Family name + イニシャルに変換
parts <- strsplit(name, " ")[[1]]
if (length(parts) == 2) {
family_name <- parts[2]
initial <- substr(parts[1], 1, 1)
return(paste(family_name, ", ", initial, ".", sep = ""))
}
# 想定外の入力の場合は元の名前をそのまま返す
return(name)
}
make_html <- function(json_parsed_list){
#
# gyoseki_name <- list(paper = "論文",presentation = "学会発表" )
# gyoseki = list(paper = NULL, presentation = NULL)
gyoseki_name <- list("査読論文",
"preprint",
"国際学会における発表 (査読あり)",
"招待セッショントーク（Invited Session Talk）",
"国内学会・シンポジウム等における発表"
)
split_list <- function(json_parsed){
index = 0
if(json_parsed$insert$type == "presentations"){
lang <- json_parsed$merge$presentation_title %>% names()
if(lang == "en"){
if(json_parsed$merge$invited){
index = 4
}else if(lang == "en" & !json_parsed$merge$invited){
index = 3
}
}else if(lang == "ja"){
index = 5
}
}else if(json_parsed$insert$type ==  "published_papers"){
if(unlist(json_parsed$merge$publication_name) %in% c("Open Science Framework")){
index = 2
}else{
index = 1
}
}
return(index)
}
json_index_vec <- json_parsed_list %>% sapply(split_list)
gyoseki <- NULL
for(j in 1:length(gyoseki_name)){
json_pared_list_tmp <- json_parsed_list[json_index_vec == j]
if(is.null(json_pared_list_tmp %>% unlist)){
}else{
gyoseki[[j]] <- json_pared_list_tmp %>% sapply(make_record)
}
}
html_top <- "<h2>業績一覧</h2>\n\n"
html_parts <- list()
for(j in 1:length(gyoseki)){
gyoseki_tmp <- gyoseki[[j]] %>% sapply(function(x) sprintf("<li>\n%s\n</li>\n", x))
html_parts[[j]] <- sprintf("<h3>%s</h3>\n<ol>\n%s</ol>",gyoseki_name[[j]],
gyoseki_tmp %>% paste0(collapse="")
)
}
c(html_top, html_parts) %>%
paste0(collapse="\n\n") %>% return()
}
make_record <- function(json_parsed){
if(json_parsed$insert$type == "presentations"){
# json_parsed$merge %>% str
list_names <- c("lang", "author", "year","title", "journal", "location", "doi", "invited_char", "type")
dat = vector("list", length(list_names)) %>%
`names<-`(list_names)
dat$lang <- json_parsed$merge$presentation_title %>% names()
# lang = "ja"
author_vec = unlist(json_parsed$merge$presenters[[dat$lang]])
if(dat$lang == "ja"){
dat$author <- paste0(author_vec, collapse = "・")
}else{
author_vec_red <- author_vec %>% sapply(convert_name)
if(length(author_vec) > 2){
dat$author <-
sprintf("%s, & %s",
paste0(author_vec_red[-length(author_vec_red)], collapse=", "),
author_vec_red[length(author_vec_red)]
)
}else{
dat$author <-
paste(author_vec_red, collapse=" & ")
}
}
dat$year  = json_parsed$merge$publication_date
dat$title = json_parsed$merge$presentation_title[[dat$lang]]
dat$journal= json_parsed$merge$event[[dat$lang]]
dat$location = json_parsed$merge$location[[dat$lang]]
# dat$journal = json_parsed$merge$publication_name
dat$volumepages = sprintf("%s(%s), %s-%s", json_parsed$merge$volume, json_parsed$merge$number, json_parsed$merge$starting_page, json_parsed$merge$ending_page)
# dat$pages = sprintf("%s-%s", json_parsed$merge$starting_page, json_parsed$merge$ending_page)
dat$doi = json_parsed$merge$identifiers$doi[[1]]
if(is.null(json_parsed$merge$volume)){
dat$volumepages = "no_volume"
}else if(json_parsed$merge$volume == "OnlineFirst"){
dat$volumepages = json_parsed$merge$volume
}
if(json_parsed$merge$invited){
dat$invited_char <- ifelse(dat$lang == "ja", "[招待]", "[invited]")
}else{
dat$invited_char <- ""
}
if(grepl("oral_presentation", json_parsed$merge$presentation_type)){
dat$type = ifelse(dat$lang == "ja", "口頭", "Oral")
}else if(json_parsed$merge$presentation_type == "poster_presentation"){
dat$type = ifelse(dat$lang == "ja", "ポスター", "Poster")
}
text <- sprintf("[%s] %s <i>%s</i>, %s, %s, %s.",
dat$type,
dat$author,
dat$title,
dat$journal,
dat$year,
dat$location)
text <- paste0(dat$invited_char, text)
# text %>% print
return(text)
}else if(json_parsed$insert$type == "published_papers"){
list_names <- c("lang", "author", "year","title", "journal", "volumepages", "doi")
dat = vector("list", length(list_names)) %>%
`names<-`(list_names)
# dat <- NULL
dat$lang =  json_parsed$merge$paper_title%>% names()
# lang = "ja"
author_vec = unlist(json_parsed$merge$authors[[dat$lang]])
if(dat$lang == "ja"){
dat$author <- paste0(author_vec, collapse = "・")
}else{
author_vec_red <- author_vec %>% sapply(convert_name)
if(length(author_vec) > 2){
dat$author <-
sprintf("%s, & %s",
paste0(author_vec_red[-length(author_vec_red)], collapse=", "),
author_vec_red[length(author_vec_red)]
)
}
}
dat$year  = json_parsed$merge$publication_date
dat$title = json_parsed$merge$paper_title[[dat$lang]]
dat$journal = json_parsed$merge$publication_name
dat$volumepages = sprintf("%s(%s), %s-%s", json_parsed$merge$volume, json_parsed$merge$number, json_parsed$merge$starting_page, json_parsed$merge$ending_page)
# dat$pages = sprintf("%s-%s", json_parsed$merge$starting_page, json_parsed$merge$ending_page)
dat$doi = json_parsed$merge$identifiers$doi[[1]]
if(1){
parse_see_also <- function(x){
# x$label == "doi"
doi <- x$`@id` %>% str_detect("doi")
osf <- x$`@id` %>% str_detect("osf")
preprint <- x$`@id` %>% str_detect("preprint")
if(preprint){
text = "preprint"
}else if(osf){
text = "osf"
}else if(doi){
# text = "doi"
return("")
}
sprintf("[%s]", html_url(url = x$`@id`, text = text))
}
urls <-
json_parsed$merge$see_also %>% sapply(parse_see_also)
dat$urls <- paste0(urls, collapse="")
}
if(is.null(json_parsed$merge$volume)){
dat$volumepages = "no_volume"
}else if(json_parsed$merge$volume == "OnlineFirst"){
dat$volumepages = json_parsed$merge$volume
}
dat
text <- sprintf("%s (%s). %s, <i>%s</i>, %s, %s. %s",
dat$author,
dat$year,
dat$title,
dat$journal,
dat$volumepages,
html_url(dat$doi, doi =T),
dat$urls)
# text %>% print
return(text)
}else{
return(NA)
}
}
json_parsed_list <-
# readLines("C:/Users/muphy/Downloads/rm_researchers20240909/rm_researchers20240909.jsonl")[14] %>%
# readLines("C:/Users/muphy/Downloads/rm_researchers20240909-1/rm_researchers20240909-1.jsonl")[12] %>%
# readLines("C:/Users/muphy/Downloads/rm_researchers20240910/rm_researchers20240910.jsonl") %>%
# readLines("C:/Users/muphy/Downloads/rm_researchers20240918/rm_researchers20240918.jsonl") %>%
readLines("C:/Users/muphy/Downloads/rm_researchers20240918-1/rm_researchers20240918-1.jsonl") %>%
lapply(jsonlite::parse_json)
# text = paste(readLines("C:/Users/muphy/マイドライブ/012myhomepage_github/publication_base.html"), collapse = "/n")
# text = sprintf(text, make_html(json_parsed_list))
#
# write(text, "C:/Users/muphy/マイドライブ/012myhomepage_github/publication.html")
write(make_html(json_parsed_list), "C:/Users/muphy/マイドライブ/012myhomepage_github/新しい頁/new/R/contents/publications_content.html")
# generate_html.R
# 必要なパッケージをロード
# install.packages("stringr") # 未インストールの場合はコメントを外す
library(stringr)
setwd("C:/Users/muphy/マイドライブ/012myhomepage_github/新しい頁/new/R")
# ヘッダーとフッターを読み込み
header_template <- readLines("templete/header.html", encoding = "UTF-8")
footer_template <- readLines("templete/footer.html", encoding = "UTF-8")
html_url <- function(url, text, doi = FALSE){
if(doi) url <- sprintf("https://doi.org/%s", url)
if(missing(text)){
text <- url
}
sprintf('<a href="%s">%s</a>', url, text)
}
html_url("https://fukushima-k.github.io/")
# news の管理
# ニュースデータ
news_data <- list(
list(
title = "新しいホームページを公開します。",
date = "2024-07",
content = paste0("新しいホームページを公開します。内容は順次更新予定です。", html_url("https://fukushima-k.github.io/"))
),
list(
title = "共同研究を開始しました。",
date = "2024-06",
content = "外部機関との共同研究を開始しました。今後、公開予定です。"
),
list(
title = "論文が採択されました。",
date = "2024-05",
content =
paste0("<i>Journal of Educational and Behavioral Statistics</i>誌に採択された論文がOnlineFirstで公開されました。", html_url("https://doi.org/10.3102/10769986241245707"))
),
list(
title = "賞を受賞しました。",
date = "2023-11",
content = "日本計算機統計学会 第37回シンポジウムにて「一般化多枝選択型認知診断モデルの提案」の題目で学生研究発表賞をいただきました。ありがとうございます。"
),
list(
title = "preprintを公開しました。",
date = "2023-07",
content = paste0("Open Science Frameworkにて、preprint \"<i>Modeling Partial Knowledge in Multiple-Choice Cognitive Diagnostic Assessment.</i>\" を公開しました。", html_url("https://doi.org/10.31234/osf.io/wefb7"))
)
# 他のニュース項目を追加
)
# ニュース項目をHTMLリストとして生成
generate_news_list <- function(news_items) {
unlist(lapply(news_items, function(item) {
paste0(
'<li class="list-group-item">',
'<h5>', item$title, '</h5>',
'<small>投稿日: ', item$date, '</small>',
'<p>', item$content, '</p>',
'</li>'
)
}))
}
# ニュースページのコンテンツ
news_page_content <- c(
'<h2>ニュース</h2>',
'<ul class="list-group">',
generate_news_list(news_data),
'</ul>'
)
# ニュースページのコンテンツファイルに書き込み
writeLines(news_page_content, "contents/news_content.html")
# 最新の3件を取得
latest_news <- news_data[1:min(3, length(news_data))]
# トップページのニュースセクション
index_news_content <- c(
'<h2>最新のニュース</h2>',
'<ul class="list-group">',
generate_news_list(latest_news),
'</ul>',
'<a href="news.html" class="btn btn-secondary mt-3">すべてのニュースを見る</a>'
)
# トップページのコンテンツファイル（例: contents/index_content.html）に埋め込む
# プレースホルダーを使用して、ニュースセクションを挿入
index_content <- readLines("contents/index_content_news_plus.html", encoding = "UTF-8")
index_content <- str_replace(index_content, fixed("{{news_section}}"), paste(index_news_content, collapse = "\n"))
writeLines(index_content, "contents/index_content_news_plus_written.html", useBytes = TRUE)
# ページ情報のリストを作成
pages <- list(
list(
filename = "index.html",
title = "心理統計学者のホームページ - ホーム",
# content_file = "contents/index_content.html",
content_file = "contents/index_content_news_plus_written.html",
active_menu = "home"
),
list(
filename = "about.html",
title = "心理統計学者のホームページ - 自己紹介",
content_file = "contents/about_content.html",
active_menu = "about"
),
list(
filename = "research.html",
title = "心理統計学者のホームページ - 研究内容",
content_file = "contents/research_content.html",
active_menu = "research"
),
list(
filename = "publications.html",
title = "心理統計学者のホームページ - 業績一覧",
content_file = "contents/publications_content.html",
active_menu = "publications"
),
list(
filename = "news.html",
title = "心理統計学者のホームページ - ニュース",
content_file = "contents/news_content.html",
active_menu = "news"
),
# list(
#   filename = "blog.html",
#   title = "心理統計学者のホームページ - ブログ",
#   content_file = "contents/blog_content.html",
#   active_menu = "blog"
# ),
list(
filename = "index_en.html",
title = "English Version - Coming Soon",
content_file = "contents/index_en_content.html",
active_menu = ""  # ヘッダーにリンクを追加しないため、active_menu は空にします
),
list(
filename = "contact.html",
title = "心理統計学者のホームページ - お問い合わせ",
content_file = "contents/contact_content.html",
active_menu = "contact"
)
)
# 各ページのHTMLを生成
for (page in pages) {
# ヘッダーのテンプレートにタイトルを挿入
header <- str_replace_all(header_template, fixed("{{title}}"), page$title)
# アクティブなメニューを設定
menu_items <- c("home", "about", "research", "publications", "blog", "contact")
for (item in menu_items) {
if (item == page$active_menu) {
header <- str_replace_all(header, fixed(paste0("{{active_", item, "}}")), "active")
} else {
header <- str_replace_all(header, fixed(paste0("{{active_", item, "}}")), "")
}
}
# コンテンツを読み込み
content <- readLines(page$content_file, encoding = "UTF-8")
# フッターをそのまま使用
footer <- footer_template
# 最終的なHTMLを組み立て
html <- c(header, content, footer)
# ファイルに書き込み
writeLines(html, page$filename, useBytes = TRUE)
cat("Generated:", page$filename, "\n")
}
